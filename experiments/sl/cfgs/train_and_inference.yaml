defaults:
  - network: si_mlp
  - dataset: australian
  # Use slurm on cluster or local?
  - override hydra/launcher: slurm
  - _self_

##### Experiment config #####
output_dim: ???
logging_epoch_freq: 2
random_seed: 117
double_train: False # if True train in double precision
double_inference: True # True for UCI and False for MNIST/FMNIST/CIFAR10
device: "cuda"

##### Training config #####
batch_size: 128
lr: 1e-4
n_epochs: 500
early_stop:
  patience: 15
  min_prior_precision: 0

##### SFR config (most of this gets overridden) #####
sfr:
  _target_: experiments.sl.utils.init_SFR_with_gaussian_prior
  _convert_: all
  prior_precision: 1e-4
  likelihood:
    _target_: src.likelihoods.CategoricalLh
    EPS: 0.0 # TODO default is 0.01
  output_dim: ${output_dim}
  num_inducing: 128
  dual_batch_size: ${dual_batch_size}
  jitter: 1e-4
  device: ${device} # TODO should this always be cpu??

##### SFR inference config #####
run_sfr_flag: True # if True runs inference with SFR
run_sfr_nn_flag: False # if True, also runs SFR with NN mean predictions
num_inducings_as_percent: True # if True treat num_inducings as percentages
num_inducings:
  - 1
  - 2
  - 5
  - 10
dual_batch_size: 1000 # needed to keep memory in check
EPS: 0.00 # 0.01 is Good for UCI
jitter: 1e-5
# BO hyperparams for SFR
posthoc_prior_opt_bo: True # if True tune prior prec with BO
num_bo_trials: 20 # 30 for UCI and 20 for MNIST/FMNIST/...
posthoc_prior_opt_grid: False # if True tune prior prec with grid search

##### Laplace inference config #####
run_laplace_flag: True # if True runs inference with Laplace
posthoc_prior_opt_laplace: True # if True tune prior prec with grid search
hessian_structures: ["diag", "kron"]

##### W&B config #####
wandb:
  group: ${dataset.name}
  project: "sfr-experiments"
  use_wandb: True
  run_name: ${dataset.name}-seed=${random_seed}-${now:%Y-%m-%d_%H-%M-%S}
  tags:
    - "dataset=${dataset.name}"
    - "seed=${random_seed}"

##### Hydra config #####
hydra:
  run:
    dir: output/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}
  job:
    chdir: true
  sweep:
    dir: ${hydra.run.dir}
    subdir: ${hydra.job.num}
  job_logging:
    root:
      level: INFO # DEBUG
